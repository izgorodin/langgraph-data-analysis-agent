# Гайд по выполнению задания: LangGraph Data Analysis LangGraph Agent

Этот документ объясняет **что**, **зачем** и **как** сделать, чтобы полностью выполнить задание «Data Analysis LangGraph Agent», а также содержит **чек‑лист самопроверки соответствия требованиям**.

---

## 1) Краткая суть задания

Построить **кастомного агента** на **LangGraph (Python)**, который анализирует публичный датасет `` в **Google BigQuery** и генерирует **бизнес‑инсайты** (сегментация клиентов, эффективность товаров, тренды и сезонность, география продаж). Интерфейс — **CLI чат**. LLM — предпочтительно **Google Gemini** (через Google AI Studio), допустим **AWS Bedrock** как альтернатива.

**Ключевая идея:** агент принимает задачу на естественном языке → строит план → синтезирует SQL → **валидирует SQL** (политики безопасности) → исполняет в BigQuery → анализирует результат (pandas) → формирует краткий отчёт с цифрами и предложениями.

---

## 2) Что сдаём (deliverables)

1. **Рабочее приложение**
   - CLI для интерактивного диалога.
   - Интеграция с **Gemini** (или Bedrock) как LLM‑бэкендом.
2. **Архитектурная документация**
   - Диаграмма на высоком уровне: узлы агента, взаимодействия, внешние сервисы.
   - Короткое описание выбора сервисов/LLM, потока данных, обработка ошибок и фолбэки.
3. **Репозиторий** (публичный или с доступом ревьюерам)
   - Исходники.
   - README с инструкциями запуска.
   - Диаграмма (Mermaid/PNG).

> ⚠️ Ограничение времени от заказчика: **4–8 часов**. Наш план ниже укладывается в этот объём.

---

## 3) Архитектура агента (высокоуровнево)

**Поток:** `plan → synthesize_sql → validate_sql → execute_sql → analyze_df → report` (+ ветки ошибок/повторов)

- **plan** — LLM превращает пользовательский запрос в минимальный JSON‑план (таблицы, метрики, срезы, фильтры).
- **synthesize\_sql** — LLM генерирует SQL (BigQuery Standard SQL) по плану и схемам таблиц.
- **validate\_sql** — парсим и проверяем SQL (только SELECT, только разрешённые таблицы, лимиты) через **sqlglot** и политики.
- **execute\_sql** — выполняем запрос в BigQuery, получаем DataFrame.
- **analyze\_df** — агрегируем краткую сводку (shape/describe/preview) и вычисляем простые KPI (опционально).
- **report** — LLM формирует лаконичный отчёт (цифры, наблюдения, 1–2 next steps).

**Внешние компоненты:**

- **BigQuery** — источник данных, схема подтягивается из `INFORMATION_SCHEMA`.
- **Gemini (google-generativeai)** — основной LLM (либо Bedrock в качестве фолбэка).

**Безопасность и эксплуатация:**

- Разрешаем только `SELECT` и whitelisted таблицы (`orders`, `order_items`, `products`, `users`).
- Ограничиваем `MAX_BYTES_BILLED` (например, 100MB для тестов).
- Включаем `use_query_cache`.
- Логируем промежуточные состояния (флаг `--verbose`).

---

## 4) Окружение и зависимости

**Python 3.10+**. Устанавливаем зависимости:

```bash
pip install -r requirements.txt
```

Ключевые пакеты:

- `langgraph` — граф состояний агента.
- `google-cloud-bigquery`, `google-auth` — доступ к BigQuery.
- `google-generativeai` — доступ к Gemini.
- `sqlglot` — парсинг/валидатор SQL.
- `pandas`, `pyarrow` — работа с результатами.
- `click`, `rich` — CLI и красивый вывод.
- `python-dotenv` — конфиг через `.env`.

---

## 5) Настройка BigQuery

1. **Аутентификация** в GCP (любой из способов):
   - `gcloud auth application-default login` (ADC), или
   - переменная `GOOGLE_APPLICATION_CREDENTIALS=/path/to/service-account.json`.
2. **Свободная квота**: BigQuery Free Tier даёт **1TB/месяц** — более чем достаточно.
3. В `.env` указать:
   - `BIGQUERY_PROJECT` — ваш GCP проект.
   - `BIGQUERY_LOCATION` — например, `US`.
   - `DATASET_ID` — `bigquery-public-data.thelook_ecommerce` (по заданию).
   - `MAX_BYTES_BILLED` — мягкий лимит (напр., `100000000`).

---

## 6) Настройка LLM (Gemini/Bedrock)

- **Gemini (рекомендуется)**: получите `GOOGLE_API_KEY` в Google AI Studio, задайте в `.env`.
- **Bedrock (опционально)**: задайте `AWS_REGION` и `BEDROCK_MODEL_ID`; добавьте реализацию вызова в `llm.py` (в starter‑коде заглушка).

---

## 7) Структура проекта (пример)

```
.
├─ README.md
├─ requirements.txt
├─ .env.example
├─ cli.py                    # CLI чат
├─ diagrams/
│  └─ architecture.mmd       # Mermaid‑диаграмма
└─ src/
   ├─ config.py              # загрузка .env, настройки
   ├─ bq.py                  # клиент BigQuery, schema/query helpers
   ├─ llm.py                 # вызовы Gemini (и фолбэк)
   └─ agent/
      ├─ state.py            # pydantic‑состояние агента
      ├─ prompts.py          # системные промпты
      ├─ nodes.py            # узлы графа (plan/sql/validate/execute/analyze/report)
      └─ graph.py            # сборка графа LangGraph
```

---

## 8) Как работает агент (детали)

### Валидация SQL (безопасность)

- Парсим SQL через **sqlglot** (диалект BigQuery);
- Запрещаем всё, кроме **SELECT**;
- Разрешаем только таблицы из белого списка;
- Для неагрегирующих запросов принудительно добавляем `LIMIT 1000`;
- Ставим ограничение `maximum_bytes_billed`.

### Добыча схемы

- Запрашиваем `INFORMATION_SCHEMA.COLUMNS` по белому списку таблиц — это делает промпты **схема‑осознанными**.

### Анализ результата

- `df.describe()` и предпросмотр `head(10)` кладём в сводку для LLM;
- По желанию добавляем детерминированные KPI (например, топ‑N, сезонные пики, негативная маржа).

### Отчёт

- LLM формирует короткий **executive summary**: 2–4 предложения с цифрами и **следующими вопросами**.

---

## 9) Запуск и примеры

### Быстрый запуск

```bash
# 1) зависимости
pip install -r requirements.txt

# 2) авторизация GCP (выберите любой метод)
gcloud auth application-default login

# 3) задать ключи в .env
cp .env.example .env
# отредактируйте .env

# 4) запуск
python cli.py --model gemini-1.5-pro
# интерактив: введите вопрос при запуске
```

### Примеры запросов

- «Сегментируй клиентов по RFM и покажи топ‑3 сегмента по выручке за 180 дней»
- «Топ‑10 товаров по прибыли за последние 90 дней; укажи margin% и категории»
- «Месячные тренды продаж по категориям, отметь месяцы с отклонением > 2σ»
- «География выручки по странам и топ‑штатам; прокомментируй сезонность»

> Рекомендация: запускать с флагом `--verbose`, чтобы увидеть промежуточные шаги (план, SQL, сводку DF).

---

## 10) Качество, ошибки и фолбэки

### Оценка качества (минимум)

- Корректность SQL (парсится и исполняется; не бьёт лимиты);
- осмысленный отчёт: **конкретные числа** из DF и 1–2 разумные «next steps»;
- отсутствие повтора одинаковых результатов (MMR снижает дубликаты на этапе выбора источников в более продвинутых версиях).

### Обработка ошибок

- **SQL parse error** → вернём пользователю короткое описание и предложим уточнить запрос;
- **BigQuery BadRequest** → показать сообщение BigQuery + рекомендацию (сузить период, уменьшить выборку);
- **Empty result** → предложить смежный фильтр/период;
- **LLM timeout** → повтор (1 раз) или «deterministic only» режим (аналитика без текста LLM).

### Fallback стратегии

- Если LLM генерирует неоднозначный SQL → вернуть план пользователю с явными доп. вопросами (grain/period/filters);
- Если Gemini недоступен → использовать Bedrock (при наличии ключей);
- Если квота BigQuery выбрана → сузить временной диапазон и предупредить пользователя.

---

## 11) Чек‑лист соответствия заданию (самопроверка)

**Функциональность**

-

**Инсайты** (примеры минимум по одному):

-

**Безопасность/надёжность**

-

**Архитектура/доки**

-

**Репозиторий**

-

Если все пункты закрыты — задание соответствует требованиям.

---

## 12) Тайм‑план на 4–8 часов

- **Час 0–1.5:** каркас проекта, конфиг, BigQuery клиент, схема.
- **Час 1.5–3:** узлы LangGraph (plan/sql/validate/execute), базовая валидация SQL.
- **Час 3–4:** анализ DF и отчёт (LLM), CLI, пример запросов.
- **Час 4–5:** документация: README, диаграмма, `.env.example`.
- **Час 5–6:** полировка/обработка ошибок, тестовые запросы, self‑check.
- **Час 6–8 (буфер):** добавочные инсайты, рефакторинг промптов, экспорт диаграммы в PNG.

---

## 13) Как демонстрировать / что показать ревьюерам

1. CLI: один запрос → показать план → SQL → `head()` → отчёт.
2. Пояснить политики безопасности SQL и лимиты BigQuery.
3. Показать диаграмму и кратко аргументировать выбор LLM/сервисов.
4. Ответить, как бы вы расширяли функциональность (RFM‑сегментация детальнее, сезонность/аномалии, карты для гео и т. п.).

---

## 14) Идеи улучшений (опционально, если останется время)

- Кеширование популярных результатов (by question hash) с TTL.
- Небольшой словарь синонимов домена (категории/регионы).
- Преднастроенные шаблоны SQL для типовых KPI (детерминированность + экономия токенов LLM).
- Вывод отчёта и таблицы в Markdown/HTML.

---

### Готово к отправке

Когда всё работает:

- Сделайте репозиторий публичным (или добавьте ревьюеров)
- Проверьте README, добавьте скрин вывода CLI
- Приложите диаграмму (PNG/MD)
- Дайте 2–3 «примерных вопросов» в README

Это обеспечит полное соответствие требованиям задания и покажет аккуратную инженерную культуру.

